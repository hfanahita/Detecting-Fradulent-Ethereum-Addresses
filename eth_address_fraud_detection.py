# -*- coding: utf-8 -*-
"""ETH Address Fraud Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ux0fuefuu4yBpoX4fkMaMRAzfZ90xOCc

#Initial Setup
"""

#importing the required libraries
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support
from statistics import mean

# Reading the data file
df = pd.read_csv('transaction_dataset.csv')
eth_df = df.copy()
df

"""#Preprocessing & EDA"""

#dropping duplicate records
eth_df = eth_df.drop_duplicates()

"""##Dropping irrelevant columns"""

eth_df.columns

#dropping columns that play the role of id
eth_df = eth_df.drop(['Index','Unnamed: 0'], axis=1)

# selecting numerical columns that have zero variance
numerical_columns = eth_df.select_dtypes(include='number').columns
zero_var = eth_df[numerical_columns].var() == 0

print(eth_df[numerical_columns].columns[zero_var])
# dropping the zero variance columns
eth_df = eth_df.drop(columns=eth_df[numerical_columns].columns[zero_var])

# dropping the categorical volumes as their values are not related for predicting the target values
categorical_columns = eth_df.select_dtypes(include='object').columns
eth_df = eth_df.drop(categorical_columns, axis = 1)


eth_df

#checking the unique values of some of the columns and their value counts
print(eth_df['max val sent to contract'].unique())
print(eth_df['max val sent to contract'].value_counts())
print(eth_df['min value sent to contract'].unique())
print(eth_df['min value sent to contract'].value_counts())
print(eth_df['avg value sent to contract'].unique())
print(eth_df['avg value sent to contract'].value_counts())
print(eth_df['total ether sent contracts'].unique())
print(eth_df['total ether sent contracts'].value_counts())

"""As the above columns' values are all 0 except for a very few records, they should be dropped:"""

eth_df = eth_df.drop(['max val sent to contract','min value sent to contract','avg value sent to contract', 'total ether sent contracts'],axis = 1)

eth_df.describe()

"""##Handling Missing Values"""

#checking for missing values
missing_values = eth_df.isnull()

#counting the missing values in each column
missing_values_count = missing_values.sum()

print("Missing values count in each column:")
print(missing_values_count)

#total number of missing values in the df
total_missing_values = missing_values.sum().sum()
print("\nTotal number of missing values:", total_missing_values)

#replacing missing values with 0
numerical_columns = eth_df.select_dtypes(include='number').columns
for column in numerical_columns:
    eth_df[column] = eth_df[column].fillna(0)

eth_df

"""##Normalization of the data: Min-Max"""

numerical_columns = eth_df.select_dtypes(include='number').columns
numerical_columns

# all numerical columns except FLAG
numerical_columns = eth_df.select_dtypes(include='number').columns[1:]

# initializing the MinMaxScaler
scaler = MinMaxScaler()

# applying Min-Max scaling
eth_df[numerical_columns] = scaler.fit_transform(eth_df[numerical_columns])


eth_df.describe()

"""##Correlation Analysis"""

# calculating the correlation between predictors
correlation = eth_df.corr()

# plotting the correlation heatmap
plt.figure(figsize=(16, 12))
sns.heatmap(correlation, cmap='RdBu', vmin = -1, vmax = 1)
plt.title('Correlation Heatmap', fontsize=16)

# table of correlation
correlation

# finding and dropping the highly correlated columns
correlated_columns = set()
# looping through the upper triangle of the correlation matrix (except the diagonal)
for i in range(len(correlation.columns)):
    for j in range(i):
        if abs(correlation.iloc[i, j]) >= 0.9:
            correlated_columns.add(correlation.columns[i])

eth_df = eth_df.drop(columns=correlated_columns)

eth_df

"""### Imbalanced Data set"""

# plotting the proportions of fraudluent and non-fraudulent cases
eth_df['FLAG'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightcoral'])
plt.title('Target distribution of being Fraudulent or not')
plt.show()

"""# Test and Train sets"""

n = 10
# defining metrics for each class
precision_0 = list(range(n))
precision_1 = list(range(n))
recall_0 = list(range(n))
recall_1 = list(range(n))
f1_score_0 = list(range(n))
f1_score_1 = list(range(n))
support_0 = list(range(n))
support_1 =list(range(n))


for i in range(10):
  # splitting the df into train and test
  df_train, df_test = train_test_split(eth_df, test_size=0.1, stratify=eth_df['FLAG'])
  x_test = df_test.iloc[:,1:]
  y_test = df_test['FLAG']

  # balancing the train set
  fraudulent_sample = df_train[df_train["FLAG"] == 1]
  non_fraudulent_sample = df_train[df_train["FLAG"] == 0].sample(len(fraudulent_sample), random_state = 42)
  balanced_data = pd.concat([non_fraudulent_sample, fraudulent_sample], axis = 0)
  y_train = balanced_data["FLAG"]
  x_train = balanced_data.iloc[:,1:]

  # initializing and training the kNN classifier
  # k=10
  knn_classifier = KNeighborsClassifier(n_neighbors=10)
  knn_classifier.fit(x_train, y_train)

  # predicting on the test set
  y_pred = knn_classifier.predict(x_test)

  # evaluation for both classes
  precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred, average=None)
  precision_0[i] = precision[0]
  precision_1[i] = precision[1]
  recall_0[i] = recall[0]
  recall_1[i] = recall[1]
  f1_score_0[i] = f1_score[0]
  f1_score_1[i] = f1_score[1]
  support_0[i] = support[0]
  support_1[i] = support[1]

# averaging the 10 individual results
precision = [mean(precision_0),mean(precision_1)]
recall = [mean(recall_0), mean(recall_1)]
f1_score = [mean(f1_score_0), mean(f1_score_1)]
support = [mean(support_0), mean(support_1)]
print(" precision: ", precision, "\n recall: ", recall, "\n f1_score: ", f1_score, "\n support: ", support)